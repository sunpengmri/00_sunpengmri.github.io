1. system: ubuntu 22.04 LTS

2. sublime text: from system
	set font size to 20

3. change apt source to ali

	sudo gedit /etc/apt/source.list

	deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse
	deb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse
	deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse
	deb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse
	deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse
	deb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse
	deb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse
	deb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse
	deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse
	deb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse

	sudo apt update
	
4. vscode
	download so slow

5. nvidia-driver & CUDA & CUDNN
	(5.1) lspci | grep -i nvidia
	(5.2) download driver: https://www.nvidia.cn/Download/index.aspx?lang=cn
	(5.3) sudo apt-get update
		  sudo apt-get install gcc
	      sudo apt-get install g++
          sudo apt-get install make
    (5.4) sudo gedit /etc/modprobe.d/blacklist.conf 
    		## add in last two lines
    		blacklist nouveau
			options nouveau modeset=0

			sudo update-initramfs -u
			lsmod | grep nouveau
	(5.5) 本人电脑惠普 按F10进入BIOS，找到安全启动项，然后禁用，电脑不同进入BIOS方式不同。
	(5.6) installation(x11 configure heiping)
		sudo telinit 3 
		sudo service gdm3 stop
		sudo chmod 777 NVIDIA-Linux-x86_64-525.60.11.run   #赋予可执行权限
		sudo ./NVIDIA-Linux-x86_64-525.60.11run  --no-opengl-files --no-x-check #安装
		sudo service gdm3 start 


	(5.7) CUDA

		# cuda 12.1
		wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
		sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600wget https://developer.download.nvidia.com/compute/cuda/12.0.1/local_installers/cuda-repo-ubuntu2204-12-0-local_12.0.1-525.85.12-1_amd64.deb
		sudo dpkg -i cuda-repo-ubuntu2204-12-0-local_12.0.1-525.85.12-1_amd64.deb
		sudo cp /var/cuda-repo-ubuntu2204-12-0-local/cuda-*-keyring.gpg /usr/share/keyrings/
		sudo apt-get update
		sudo apt-get -y install cuda

		# cuda 11.7
		use .run to install 

		# CUDA：
	export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}
	export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

	(5.8) CUDNN

	wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
	sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
	wget https://developer.download.nvidia.com/compute/cuda/11.7.1/local_installers/cuda-repo-ubuntu2204-11-7-local_11.7.1-515.65.01-1_amd64.deb
	sudo dpkg -i cuda-repo-ubuntu2204-11-7-local_11.7.1-515.65.01-1_amd64.deb
	sudo cp /var/cuda-repo-ubuntu2204-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/
	sudo apt-get update
	sudo apt-get -y install cuda

6. anaconda
	set path in .bashrc

7. creat Deep Learning conda env
	conda create -n dl
	conda activate dl

	conda create -n mri python=3.8.12
	conda activate mri


8. pytorch
	conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia

9. monai
	monai installed
	monailabel to be install

10. fsl
	python fslinstall.py


11. freesurfer
	~/opt/freesurfer

12. mrtrix3
	conda install mrtrix3 -c mrtrix3

	(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib$ sudo mkdir dri`(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib$ cd dri
	(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib/dri$ sudo ln -s /usr/lib/x86_64-linux-gnu/dri/iris_dri.so iris_dri.so 

	conda install libstdcxx-ng=12.1.0 -c conda-forge

13. ANTs
	
14. hosts 配置: 20240411
	https://sites.ipaddress.com/github.global.ssl.fastly.net
	
	sudo vim /etc/hosts
	140.82.114.3      github.com
	151.101.1.194      github.global.ssl.fastly.net
	151.101.65.194     github.global.ssl.fastly.net
	151.101.129.194    github.global.ssl.fastly.net
	151.101.193.194    github.global.ssl.fastly.net
	185.199.108.153    assets-cdn.github.com
	185.199.109.153    assets-cdn.github.com
	185.199.110.153    assets-cdn.github.com
	185.199.111.153    assets-cdn.github.com

	sudo systemctl restart NetworkManager
	resolvectl statistics #查询
 	resolvectl flush-caches #刷新缓存

15. ## 下载v2ray-core
	wget -o /tmp/v2ray-linux-64.zip https://github.com/v2fly/v2ray-core/releases/download/v5.13.0/v2ray-linux-64.zip

	sudo unzip /tmp/v2ray-linux-64.zip -d /usr/local/v2ray-core
		# 有用户反馈在kali系统系统中，实际使用的geoip.dat和geosite.dat位于/usr/local/share/v2ray/
		# 所以如果有必要可以拷贝一份dat文件到/usr/local/share/v2ray/
		sudo mv /usr/local/v2ray-core/*dat /usr/local/share/v2ray/

	# 下载debian安装包, 针对不同的硬件架构以下下载命令稍做调整即可.
	# 所有安装包可以在这里找到https://github.com/v2rayA/v2rayA/releases/
	wget -o /tmp/installer_debian_x64_2.2.4.6.deb https://github.com/v2rayA/v2rayA/releases/download/v2.2.4.6/installer_debian_x64_2.2.4.6.deb

	# 安装v2rayA
	sudo apt install /tmp/installer_debian_x64_2.2.4.6.deb

	3.1. 配置 v2rayA
	修改/etc/default/v2raya配置文件让 v2raya 使用 v2ray-core

	# vi /etc/default/v2raya

	# 添加配置两行配置
	V2RAYA_V2RAY_BIN=/usr/local/v2ray-core/v2ray
	V2RAYA_V2RAY_CONFDIR=/usr/local/v2ray-core

16. 对整个目录中的文件做dos2unix操作:
	$ find . -type f -exec dos2unix {} \;



1. docker: sudo apt  install docker.io
	sudo docker ps 
	docker stop

2. change dns and host to access nvidia
	
	sudo vim /etc/systemd/resolved.conf
	[Resolve]
	DNS=114.114.114.114
	DNS=8.8.8.8
	#FallbackDNS=
	#Domains=
	#LLMNR=no
	#MulticastDNS=no
	#DNSSEC=no
	#Cache=yes
	systemctl restart systemd-resolved.service
	systemd-resolve --status


	sudo vim /etc/hosts
	185.199.111.153 nvidia.github.io
	185.199.108.153 nvidia.github.io
	sudo systemd-resolve --flush-caches

3. CUDA 11.3 and CUDNN

	wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
	sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
	wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda-repo-ubuntu2004-11-4-local_11.4.0-470.42.01-1_amd64.deb
	sudo dpkg -i cuda-repo-ubuntu2004-11-4-local_11.4.0-470.42.01-1_amd64.deb
	sudo apt-key add /var/cuda-repo-ubuntu2004-11-4-local/7fa2af80.pub
	sudo apt-get update
	sudo apt-get -y install cuda

	https://developer.nvidia.com/cudnn

		到目前为止pytorch好像还是只支持到10.2 / 11.3，可以考虑在linux/其他os下安装多版本cuda并进行切换举例： Ubuntu下可以再装个11.3/11.2版本的cuda，以支持pytorch gpu1.去nvidia官网下载，并安装对应版本的cuda，并进行配置
		2.cuda symbol link的选择（首次安装，选y，安装额外的版本，选n）
		3.如果需要切换cuda version，进入/usr/local，移除cuda这个symbolic link，然后再重新链接需要的versioncd /usr/local

		sudo rm -rf cuda
		sudo ln -s /usr/local/cuda-11.3 /usr/local/cuda
		4.安装对应cuda版本的pytorch，在官网选择相应的条件，并复制安装命令
		5.测试pytorch以及pytorch_gpu

5. pytorch: in anaconda(base) and monai

6. tensorflow: in anaconda(tensorflow)
4. Nvidia Clara (/home/peng/github/01_AI/05_clara/clara-train-examples)
	a. docker install and hosts setup
	b. using script to install Docker in script/installDocker.sh
	c. using clara-train-examples as a start
	d. start docker and jupyter script/startClaraTrainNoteBooks.sh
	e. in Jupyter: start terminal, then: AIAA start -w /claraDevDay/AIAA/workspace/ --engine AIAA &
	f. using jupyter notebook and slicer3D
	h. finish: 1. delete model; 2. ./stopClaraTrainNoteBooks.sh 
	i. load model: 
		1. !curl -X PUT "http://127.0.0.1:5000/admin/model/clara_pt_liver_and_tumor_ct_segmentation" -F 'ngc={"path":"nvidia/med/clara_pt_liver_and_tumor_ct_segmentation","version":"1"}'
		2. modelName="lung"
			modelFolderPath="/claraDevDay/AIAA/DownloadsFromNGC/clara_pt_covid19_ct_lung_segmentation/models/model.ts"
			configFolderPath="/claraDevDay/AIAA/DownloadsFromNGC/clara_pt_covid19_ct_lung_segmentation/config/config_aiaa.json"
			!AIAA load $modelName config $configFolderPath $modelFolderPath 

6. matlab: opt/MATLAB
7. anaconda: 
		base: python3.9
			pytorch
			pip install monai Successfully installed monai-0.8.1
			pip install monailabel 
			pip install monai-deploy-app-sdk : some errors?
			pip install koila
				只需在第一行代码，也就是把输入用lazy张量wrap起来，并指定bacth维度——koila就能自动帮你计算剩余的GPU内存并使用正确的batch size了。在本例中，batch=0，则修改如下： input = lazy(torch.randn(8, 28, 28), batch=0)完事儿！就这样和PyTorch“炼丹”时的OOM报错说拜拜。
		
		tensorflow: python3.7
			sudo pip install tensorflow  -i https://pypi.tuna.tsinghua.edu.cn/simple

		
		mri :python3.8
			dipy pip install dipy  -i https://pypi.tuna.tsinghua.edu.cn/simple 
					Successfully installed dipy-1.5.0 h5py-3.6.0 nibabel-3.2.2 numpy-1.22.3 packaging-21.3 pyparsing-3.0.8 scipy-1.8.0 tqdm-4.64.0

			conda install -c mrtrix3 mrtrix3

			R: install.packages("devtools")
			rstudio: should be started in terminal
			fae:
			matrix3:
			fsl:
				
8. pycharm

### mri
9. dpabi: should install docker and install the image
10. fsl:
	sudo $FSLDIR/fslpython/bin/conda update -n fslpython -c conda-forge --update-all fsleyes
11. afni
12. slicer3D:
13. MricronGL: MRIcroGL
14. lcmodel :    
	a. cd $HOME/.lcmodel
	b. ./lcmgui
15. ants: finished, show download some package from github
	/home/mri/opt/ants/antsbin/bin
16. qsiprep-docker

17. sudo apt install terminator

	sudo add-apt-repository ppa:gnome-terminator
	sudo apt update
	sudo apt install terminator

	安装完成后我们设置其为默认终端，通过快捷键Ctrl+Alt+T即可唤起。 网上有不同的配置方法，推荐使用以下方法：
	gsettings set org.gnome.desktop.default-applications.terminal exec /usr/bin/terminator
	gsettings set org.gnome.desktop.default-applications.terminal exec-arg "-x"

	如果想换回默认的设置(感谢 @蒋Andy 帮忙指正)：
	gsettings reset org.gnome.desktop.default-applications.terminal exec
	gsettings reset org.gnome.desktop.default-applications.terminal exec-arg

18. sudo apt install mlocate

19. sudo apt install meld: meld

20. Slicer3D:opt, need qt5 sudo apt-get install qt5-default 

21. sudo apt install cmake

22. sudo apt install aria2: 
	aria2c -i uris.txt
	aria2c http://example.org/mylinux.iso
	aria2c http://a/f.iso ftp://b/f.iso
	aria2c -x2 http://a/f.iso
	aria2c http://example.org/mylinux.torrent
	aria2c 'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C'

23. 




